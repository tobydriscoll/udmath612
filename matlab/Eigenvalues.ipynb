{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues\n",
    "\n",
    "## Eigenvalue decomposition\n",
    "\n",
    "When it exists, the eigenvalue decomposition (EVD) expresses a square matrix $A$ as a change of basis (in both source and image spaces) to a  diagonal matrix: $A=XDX^{-1}$. There are two major syntaxes. If you call `eig`, you get the complete EVD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam =\n",
      "   34.0000\n",
      "    8.9443\n",
      "   -8.9443\n",
      "   -0.0000\n",
      "X =\n",
      "   -0.5000   -0.8236    0.3764   -0.2236\n",
      "   -0.5000    0.4236    0.0236   -0.6708\n",
      "   -0.5000    0.0236    0.4236    0.6708\n",
      "   -0.5000    0.3764   -0.8236    0.2236\n"
     ]
    }
   ],
   "source": [
    "A = [\n",
    "    16     2     3    13\n",
    "     5    11    10     8\n",
    "     9     7     6    12\n",
    "     4    14    15     1\n",
    "\n",
    "];\n",
    "[X,D] = eig(A);\n",
    "lam = diag(D)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, the output is guaranteed only to satisfy $AX=XD$, which holds for defective as well as diagonalizable matrices. (But defectiveness is a \"probability zero\" event and is not robust to floating point perturbations.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam =\n",
      "     5\n",
      "     5\n",
      "     5\n",
      "     5\n",
      "ans =\n",
      "     1\n"
     ]
    }
   ],
   "source": [
    "A = 5*eye(4) + diag([1;1;1],1);   % 4x4 Jordan block\n",
    "[X,D] = eig(A);\n",
    "lam = diag(D)\n",
    "rank(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residual =\n",
      "   1.5384e-15\n"
     ]
    }
   ],
   "source": [
    "residual = norm(A*X-X*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can request the eigenvalues alone if you give just a single output to `eig`. This can be significantly faster than the full EVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schur factorization\n",
    "\n",
    "The EVD has some serious drawbacks as a target for numerical computation. First, it does not exist for every square matrix. And second, if it exists but the condition number of the eigenvalue matrix is large, it will be very sensitive to roundoff. A stable alternative is the **Schur factorization** $A=QTQ^*$, in which $Q$ is unitary and $T$ is upper triangular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T =\n",
      "   65.0000    0.0000   -0.0000    0.0000   -0.0000\n",
      "         0  -21.2768   -2.5888    2.1871   -3.4893\n",
      "         0         0  -13.1263   -3.3845   -2.8239\n",
      "         0         0         0   21.2768    2.6287\n",
      "         0         0         0         0   13.1263\n"
     ]
    }
   ],
   "source": [
    "A = [\n",
    "    17    24     1     8    15\n",
    "    23     5     7    14    16\n",
    "     4     6    13    20    22\n",
    "    10    12    19    21     3\n",
    "    11    18    25     2     9\n",
    "];\n",
    "\n",
    "[Q,T] = schur(A);\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Schur form always exists, it still reveals the eigenvalues of $A$, and it involves only stable unitary transformations. \n",
    "\n",
    "There is one quirk. If $A$ is real but has complex eigenvalues, there is an alternate form in which $T$ is \"quasitriangular.\" Each real eigenvalue appears along the diagonal of $T$, but complex conjugate pairs are represented as $2\\times 2$ real blocks along the diagonal. This allows the entire factorizaton to be done in real arithmetic, which can improve speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "  65.0000 + 0.0000i\n",
      "   0.0000 +21.2768i\n",
      "   0.0000 -21.2768i\n",
      "   0.0000 +13.1263i\n",
      "   0.0000 -13.1263i\n"
     ]
    }
   ],
   "source": [
    "A = rot90(A); \n",
    "eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T =\n",
      "   65.0000   -0.0000    0.0000   -0.0000   -0.0000\n",
      "         0    0.0000   20.9795    6.8026    0.0000\n",
      "         0  -21.5782    0.0000   -0.0000   -1.7035\n",
      "         0         0         0    0.0000   13.4714\n",
      "         0         0         0  -12.7900    0.0000\n"
     ]
    }
   ],
   "source": [
    "[Q,T] = schur(A);\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "   0.0000 +21.2768i\n",
      "   0.0000 -21.2768i\n"
     ]
    }
   ],
   "source": [
    "eig(T(2:3,2:3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessenbergification\n",
    "\n",
    "Eigenvalue algorithms are iterative. The iterative steps can be performed a lot faster if the matrix has structural zeros. Hence before iteration begins, an orthogonal similarity transformation is used to get an **upper Hessenberg** matrix with the same eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H =\n",
      "   15.0000  -12.2967  -25.7440    3.8568    1.0776\n",
      "  -30.4959   34.5430   16.0572   -7.0391   -1.1312\n",
      "         0   33.2719   17.3227    3.9749   -2.2465\n",
      "         0         0  -10.6355   -0.0167  -17.4078\n",
      "         0         0         0   13.8061   -1.8490\n"
     ]
    }
   ],
   "source": [
    "H = hess(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "  65.0000 + 0.0000i\n",
      "   0.0000 +21.2768i\n",
      "   0.0000 -21.2768i\n",
      "   0.0000 +13.1263i\n",
      "   0.0000 -13.1263i\n"
     ]
    }
   ],
   "source": [
    "eig(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $A=QHQ^*$ is \"nearly\" a Schur factorization. All that remains to be done is to make the subdiagonal zero. \n",
    "\n",
    "If $A$ is hermitian, then since the transformation preserves symmetry the resulting $H$ is actually hermitian and tridiagonal. This leads to even greater speedup in eigenvalue computations; for this and other reasons, one might even consider the hermitian and nonhermitian problems to be of distinct species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "    0.1631    3.2854         0         0         0\n",
      "    3.2854    4.8747    1.5240         0         0\n",
      "         0    1.5240    0.4987   -7.5820         0\n",
      "         0         0   -7.5820  102.4634  -54.0925\n",
      "         0         0         0  -54.0925   22.0000\n"
     ]
    }
   ],
   "source": [
    "A = A+A';\n",
    "hess(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer product interpretation\n",
    "\n",
    "We can view the diagonalization $A=XDX^{-1}$ as $A=XDY^*$, where $Y^*X=I$. The rows of $Y^*$ are known as **left eigenvectors** of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y =\n",
      "   -0.5000   -0.9340   -0.1840   -0.2236\n",
      "   -0.5000    0.6840    0.4340   -0.6708\n",
      "   -0.5000    0.4340    0.6840    0.6708\n",
      "   -0.5000   -0.1840   -0.9340    0.2236\n"
     ]
    }
   ],
   "source": [
    "A = [\n",
    "    16     2     3    13\n",
    "     5    11    10     8\n",
    "     9     7     6    12\n",
    "     4    14    15     1\n",
    "\n",
    "];\n",
    "[X,D] = eig(A);\n",
    "Y = inv(X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "  -17.0000  -17.0000  -17.0000  -17.0000\n",
      "ans =\n",
      "  -17.0000  -17.0000  -17.0000  -17.0000\n"
     ]
    }
   ],
   "source": [
    "Y(:,1)'*A\n",
    "D(1,1)*Y(:,1)' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are also the (right) eigenvectors of $A^*$. (If $A^*=A$, then of course $X=Y$ is orthogonal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "  -17.0000\n",
      "  -17.0000\n",
      "  -17.0000\n",
      "  -17.0000\n",
      "ans =\n",
      "  -17.0000\n",
      "  -17.0000\n",
      "  -17.0000\n",
      "  -17.0000\n"
     ]
    }
   ],
   "source": [
    "A'*Y(:,1)\n",
    "D(1,1)*Y(:,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can write $A=\\sum \\lambda_k x_k y_k^*$. While this is interesting, so far I don't know if it's very useful to us. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
