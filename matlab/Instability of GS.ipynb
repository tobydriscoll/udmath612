{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instability of Gramâ€“Schmidt\n",
    "\n",
    "Both forms of Gram-Schmidt orthogonalization suffer from instability when used in finite precision. Here are our reference implementations again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function [Q,R] = cgs(A)\n",
      "    [m,n] = size(A);\n",
      "    Q = zeros(m,n);\n",
      "    R = zeros(n,n);\n",
      "    for j = 1:n\n",
      "        v = A(:,j);\n",
      "        for k = 1:j-1\n",
      "            R(k,j) = Q(:,k)'*A(:,j);\n",
      "            v = v - R(k,j)*Q(:,k);\n",
      "        end\n",
      "        R(j,j) = norm(v);\n",
      "        Q(:,j) = v/R(j,j);\n",
      "    end\n",
      "end  \n",
      "\n",
      "function [Q,R] = mgs(A)\n",
      "    [m,n] = size(A);\n",
      "    Q = zeros(m,n);\n",
      "    R = zeros(n,n);\n",
      "    for k = 1:n\n",
      "        R(k,k) = norm(A(:,k));\n",
      "        Q(:,k) = A(:,k)/R(k,k);\n",
      "        for j = k+1:n\n",
      "            R(k,j) = Q(:,k)'*A(:,j);\n",
      "        end\n",
      "        A = A - Q(:,k)*R(k,:);\n",
      "    end\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "type cgs\n",
    "type mgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try these out on *Vandermonde* matrices. Given a vector $x$ of $m$ points, the columns of a Vandermonde matrix are evaluations of the monomials $1,x,\\ldots,x^{m-1}$, each at all of the points in $x$. For convenience we write a function that makes these matrices using equally spaced points in $[0,1]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test we will use is solving square linear systems of the form $Ax=b$ for vector $x$. If $A=QR$ is a full factorization, then $Rx=Q^*b$ and $x=R^{-1}Q^*b$. In practice we don't compute inverse matrices. Instead, since $R$ is triangular, we can use backward substitution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "function x = backsub(R,v)\n",
      "    x = zeros(size(v));\n",
      "    n = length(x);\n",
      "    for i = n:-1:1\n",
      "        x(i) = (v(i) - R(i,i+1:n)*x(i+1:n))/R(i,i);\n",
      "    end\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "type backsub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our experiment with MGS. For each $m$, we define a linear system whose solution we know exactly, and evaluate the accuracy of the result obtained by solving the system with an MGS factorization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 3: relative error in x is 6.410e-16\n",
      "m = 4: relative error in x is 1.010e-13\n",
      "m = 5: relative error in x is 3.150e-12\n",
      "m = 6: relative error in x is 3.963e-10\n",
      "m = 7: relative error in x is 1.459e-08\n",
      "m = 8: relative error in x is 2.619e-06\n",
      "m = 9: relative error in x is 5.191e-05\n",
      "m = 10: relative error in x is 1.114e-02\n",
      "m = 11: relative error in x is 2.629e-02\n",
      "m = 12: relative error in x is 1.748e+01\n"
     ]
    }
   ],
   "source": [
    "for m = 3:12\n",
    "    A = vander((0:m-1)/(m-1));\n",
    "    [Q,R] = mgs(A);\n",
    "    xact = ones(m,1);\n",
    "    b = A*xact;\n",
    "    x = backsub(R,Q'*b);\n",
    "    fprintf(\"m = %d: relative error in x is %.3e\\n\",m,(norm(x-xact)/norm(xact)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, these don't look so good as $m$ increases. But as we will be seeing, we cannot always expect accurate solutions to this type of problem. Let's assume that the built-in QR factorization is as good as we can do, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 3: relative error in x is 2.937e-16\n",
      "m = 4: relative error in x is 9.989e-15\n",
      "m = 5: relative error in x is 8.352e-15\n",
      "m = 6: relative error in x is 2.258e-13\n",
      "m = 7: relative error in x is 5.217e-13\n",
      "m = 8: relative error in x is 1.608e-12\n",
      "m = 9: relative error in x is 9.540e-12\n",
      "m = 10: relative error in x is 4.794e-10\n",
      "m = 11: relative error in x is 1.487e-09\n",
      "m = 12: relative error in x is 3.415e-08\n"
     ]
    }
   ],
   "source": [
    "for m = 3:12\n",
    "    A = vander((0:m-1)/(m-1));\n",
    "    [Q,R] = qr(A);\n",
    "    xact = ones(m,1);\n",
    "    b = A*xact;\n",
    "    x = backsub(R,Q'*b);\n",
    "    fprintf(\"m = %d: relative error in x is %.3e\\n\",m,(norm(x-xact)/norm(xact)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So clearly, MGS is not as accurate as it could be! But CGS is even worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 3: relative error in x is 5.439e-16\n",
      "m = 4: relative error in x is 7.792e-14\n",
      "m = 5: relative error in x is 1.365e-11\n",
      "m = 6: relative error in x is 1.851e-09\n",
      "m = 7: relative error in x is 4.174e-06\n",
      "m = 8: relative error in x is 6.338e-03\n",
      "m = 9: relative error in x is 5.289e+00\n",
      "m = 10: relative error in x is 4.211e+04\n",
      "m = 11: relative error in x is 3.899e+05\n",
      "m = 12: relative error in x is 9.623e+05\n"
     ]
    }
   ],
   "source": [
    "for m = 3:12\n",
    "    A = vander((0:m-1)/(m-1));\n",
    "    [Q,R] = cgs(A);\n",
    "    xact = ones(m,1);\n",
    "    b = A*xact;\n",
    "    x = backsub(R,Q'*b);\n",
    "    fprintf(\"m = %d: relative error in x is %.3e\\n\",m,(norm(x-xact)/norm(xact)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we dig a little deeper, we find more detail about what is happening. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 3\n",
      "    MGS: norm(A-QR) = 0.00e+00, norm(Q'Q-I) = 4.85e-17\n",
      "    CGS: norm(A-QR) = 1.11e-16, norm(Q'Q-I) = 1.24e-16\n",
      "m = 4\n",
      "    MGS: norm(A-QR) = 1.11e-16, norm(Q'Q-I) = 1.25e-15\n",
      "    CGS: norm(A-QR) = 0.00e+00, norm(Q'Q-I) = 2.26e-15\n",
      "m = 5\n",
      "    MGS: norm(A-QR) = 2.22e-16, norm(Q'Q-I) = 8.58e-15\n",
      "    CGS: norm(A-QR) = 3.14e-16, norm(Q'Q-I) = 3.13e-13\n",
      "m = 6\n",
      "    MGS: norm(A-QR) = 2.25e-16, norm(Q'Q-I) = 9.00e-14\n",
      "    CGS: norm(A-QR) = 2.02e-16, norm(Q'Q-I) = 1.20e-11\n",
      "m = 7\n",
      "    MGS: norm(A-QR) = 2.49e-16, norm(Q'Q-I) = 5.16e-13\n",
      "    CGS: norm(A-QR) = 1.64e-16, norm(Q'Q-I) = 8.18e-09\n",
      "m = 8\n",
      "    MGS: norm(A-QR) = 2.78e-16, norm(Q'Q-I) = 1.11e-11\n",
      "    CGS: norm(A-QR) = 2.66e-16, norm(Q'Q-I) = 2.86e-06\n",
      "m = 9\n",
      "    MGS: norm(A-QR) = 3.35e-16, norm(Q'Q-I) = 3.22e-11\n",
      "    CGS: norm(A-QR) = 3.73e-16, norm(Q'Q-I) = 5.01e-04\n",
      "m = 10\n",
      "    MGS: norm(A-QR) = 4.63e-16, norm(Q'Q-I) = 8.67e-10\n",
      "    CGS: norm(A-QR) = 5.93e-16, norm(Q'Q-I) = 4.47e-01\n",
      "m = 11\n",
      "    MGS: norm(A-QR) = 4.17e-16, norm(Q'Q-I) = 2.82e-10\n",
      "    CGS: norm(A-QR) = 4.37e-16, norm(Q'Q-I) = 1.74e+00\n",
      "m = 12\n",
      "    MGS: norm(A-QR) = 5.51e-16, norm(Q'Q-I) = 2.38e-08\n",
      "    CGS: norm(A-QR) = 4.98e-16, norm(Q'Q-I) = 3.73e+00\n"
     ]
    }
   ],
   "source": [
    "for m = 3:12\n",
    "    A = vander((0:m-1)/(m-1));\n",
    "    [Q,R] = mgs(A);\n",
    "    fprintf(\"m = %d\\n\",m)\n",
    "    fprintf(\"    MGS: norm(A-QR) = %.2e, norm(Q'Q-I) = %.2e\\n\",(norm(A-Q*R)),(norm(Q'*Q-eye(m))))\n",
    "    [Q,R] = cgs(A);\n",
    "    fprintf(\"    CGS: norm(A-QR) = %.2e, norm(Q'Q-I) = %.2e\\n\",(norm(A-Q*R)),(norm(Q'*Q-eye(m))))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both algorithms produce matrices such that $QR\\approx A$. However, they do a poor job at ensuring that $Q$ is orthogonal/unitary. As it happens, this problem in CGS is much more severe, and it also gets a poor $R$, unlike MGS.\n",
    "\n",
    "When one algorithm used in finite precision has solutions with much greater error than can be obtained through a different method, we say the algorithm is *unstable*. We will have a lot more to say on this subject soon. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
